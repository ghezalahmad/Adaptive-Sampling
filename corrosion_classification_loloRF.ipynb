{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Specimen\n",
       "1    1210\n",
       "2     744\n",
       "Name: Label, dtype: int64"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Reload the dataset\n",
    "data = pd.read_excel('open_crosion.xlsx')\n",
    "\n",
    "# Group data by specimen number and count the number of positive class samples in each specimen\n",
    "specimen_counts = data.groupby('Specimen')['Label'].sum()\n",
    "\n",
    "specimen_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([[1], [2]], [])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Identify specimens with only negative classes\n",
    "negative_class_specimens = specimen_counts[specimen_counts == 0].index\n",
    "\n",
    "# Create custom k-fold splits based on the described criteria\n",
    "positive_class_specimens = [1, 2]\n",
    "folds = []\n",
    "\n",
    "# Iterate to create folds\n",
    "for i, pos_specimen in enumerate(positive_class_specimens):\n",
    "    fold = [pos_specimen]\n",
    "    # Add two negative class specimens to the fold\n",
    "    fold.extend(negative_class_specimens[i*2:i*2+2])\n",
    "    folds.append(fold)\n",
    "\n",
    "# Leftover specimens\n",
    "leftovers = list(set(data['Specimen'].unique()) - set([item for sublist in folds for item in sublist]))\n",
    "\n",
    "folds, leftovers\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from py4j.java_gateway import launch_gateway\n",
    "\n",
    "# Start the JVM with increased heap space\n",
    "port = launch_gateway(javaopts=['-Xmx6g'])  # Set to 4GB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lolopy.learners import RandomForestRegressor\n",
    "lolo_rf = RandomForestRegressor()\n",
    "#lolo_rf.fit(X_train.values, y_train.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "ename": "Py4JJavaError",
     "evalue": "An error occurred while calling o24.train.\n: java.lang.OutOfMemoryError: Java heap space\r\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mPy4JJavaError\u001b[0m                             Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[18], line 22\u001b[0m\n\u001b[0;32m     19\u001b[0m X_test_fold, y_test_fold \u001b[39m=\u001b[39m get_data_for_fold(data, test_specimens)\n\u001b[0;32m     21\u001b[0m \u001b[39m# Train the model\u001b[39;00m\n\u001b[1;32m---> 22\u001b[0m lolo_rf\u001b[39m.\u001b[39;49mfit(X_train_fold\u001b[39m.\u001b[39;49mvalues, y_train_fold\u001b[39m.\u001b[39;49mvalues)\n\u001b[0;32m     24\u001b[0m \u001b[39m# Predict on the test set\u001b[39;00m\n\u001b[0;32m     25\u001b[0m predictions, uncertainties \u001b[39m=\u001b[39m lolo_rf\u001b[39m.\u001b[39mpredict(X_test_fold\u001b[39m.\u001b[39mvalues, return_std\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n",
      "File \u001b[1;32mc:\\Users\\gzia\\Documents\\GitHub\\reincarnate_wp2\\.wp2\\Lib\\site-packages\\lolopy\\learners.py:96\u001b[0m, in \u001b[0;36mBaseLoloLearner.fit\u001b[1;34m(self, X, y, weights, random_seed)\u001b[0m\n\u001b[0;32m     93\u001b[0m \u001b[39m# Train the model\u001b[39;00m\n\u001b[0;32m     94\u001b[0m rng \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mgateway\u001b[39m.\u001b[39mjvm\u001b[39m.\u001b[39mio\u001b[39m.\u001b[39mcitrine\u001b[39m.\u001b[39mlolo\u001b[39m.\u001b[39mutil\u001b[39m.\u001b[39mLoloPyRandom\u001b[39m.\u001b[39mgetRng(random_seed) \u001b[39mif\u001b[39;00m random_seed \\\n\u001b[0;32m     95\u001b[0m     \u001b[39melse\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mgateway\u001b[39m.\u001b[39mjvm\u001b[39m.\u001b[39mio\u001b[39m.\u001b[39mcitrine\u001b[39m.\u001b[39mlolo\u001b[39m.\u001b[39mutil\u001b[39m.\u001b[39mLoloPyRandom\u001b[39m.\u001b[39mgetRng()\n\u001b[1;32m---> 96\u001b[0m result \u001b[39m=\u001b[39m learner\u001b[39m.\u001b[39;49mtrain(training_data, rng)\n\u001b[0;32m     98\u001b[0m \u001b[39m# Unlink the training data, which is no longer needed (to save memory)\u001b[39;00m\n\u001b[0;32m     99\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mgateway\u001b[39m.\u001b[39mdetach(training_data)\n",
      "File \u001b[1;32mc:\\Users\\gzia\\Documents\\GitHub\\reincarnate_wp2\\.wp2\\Lib\\site-packages\\py4j\\java_gateway.py:1322\u001b[0m, in \u001b[0;36mJavaMember.__call__\u001b[1;34m(self, *args)\u001b[0m\n\u001b[0;32m   1316\u001b[0m command \u001b[39m=\u001b[39m proto\u001b[39m.\u001b[39mCALL_COMMAND_NAME \u001b[39m+\u001b[39m\\\n\u001b[0;32m   1317\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcommand_header \u001b[39m+\u001b[39m\\\n\u001b[0;32m   1318\u001b[0m     args_command \u001b[39m+\u001b[39m\\\n\u001b[0;32m   1319\u001b[0m     proto\u001b[39m.\u001b[39mEND_COMMAND_PART\n\u001b[0;32m   1321\u001b[0m answer \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mgateway_client\u001b[39m.\u001b[39msend_command(command)\n\u001b[1;32m-> 1322\u001b[0m return_value \u001b[39m=\u001b[39m get_return_value(\n\u001b[0;32m   1323\u001b[0m     answer, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mgateway_client, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtarget_id, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mname)\n\u001b[0;32m   1325\u001b[0m \u001b[39mfor\u001b[39;00m temp_arg \u001b[39min\u001b[39;00m temp_args:\n\u001b[0;32m   1326\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mhasattr\u001b[39m(temp_arg, \u001b[39m\"\u001b[39m\u001b[39m_detach\u001b[39m\u001b[39m\"\u001b[39m):\n",
      "File \u001b[1;32mc:\\Users\\gzia\\Documents\\GitHub\\reincarnate_wp2\\.wp2\\Lib\\site-packages\\py4j\\protocol.py:326\u001b[0m, in \u001b[0;36mget_return_value\u001b[1;34m(answer, gateway_client, target_id, name)\u001b[0m\n\u001b[0;32m    324\u001b[0m value \u001b[39m=\u001b[39m OUTPUT_CONVERTER[\u001b[39mtype\u001b[39m](answer[\u001b[39m2\u001b[39m:], gateway_client)\n\u001b[0;32m    325\u001b[0m \u001b[39mif\u001b[39;00m answer[\u001b[39m1\u001b[39m] \u001b[39m==\u001b[39m REFERENCE_TYPE:\n\u001b[1;32m--> 326\u001b[0m     \u001b[39mraise\u001b[39;00m Py4JJavaError(\n\u001b[0;32m    327\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mAn error occurred while calling \u001b[39m\u001b[39m{0}\u001b[39;00m\u001b[39m{1}\u001b[39;00m\u001b[39m{2}\u001b[39;00m\u001b[39m.\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39m\n\u001b[0;32m    328\u001b[0m         \u001b[39mformat\u001b[39m(target_id, \u001b[39m\"\u001b[39m\u001b[39m.\u001b[39m\u001b[39m\"\u001b[39m, name), value)\n\u001b[0;32m    329\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    330\u001b[0m     \u001b[39mraise\u001b[39;00m Py4JError(\n\u001b[0;32m    331\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mAn error occurred while calling \u001b[39m\u001b[39m{0}\u001b[39;00m\u001b[39m{1}\u001b[39;00m\u001b[39m{2}\u001b[39;00m\u001b[39m. Trace:\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m{3}\u001b[39;00m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39m\n\u001b[0;32m    332\u001b[0m         \u001b[39mformat\u001b[39m(target_id, \u001b[39m\"\u001b[39m\u001b[39m.\u001b[39m\u001b[39m\"\u001b[39m, name, value))\n",
      "\u001b[1;31mPy4JJavaError\u001b[0m: An error occurred while calling o24.train.\n: java.lang.OutOfMemoryError: Java heap space\r\n"
     ]
    }
   ],
   "source": [
    "# Assuming 'Label' is the target variable and the rest are features\n",
    "X = data.drop('Label', axis=1)\n",
    "y = data['Label']\n",
    "\n",
    "# Function to extract data based on the custom fold\n",
    "def get_data_for_fold(data, fold):\n",
    "    fold_data = data[data['Specimen'].isin(fold)]\n",
    "    X_fold = fold_data.drop('Label', axis=1)\n",
    "    y_fold = fold_data['Label']\n",
    "    return X_fold, y_fold\n",
    "\n",
    "# Train and test using custom folds\n",
    "for i, fold in enumerate(folds):\n",
    "    # Split the data\n",
    "    X_train_fold, y_train_fold = get_data_for_fold(data, fold)\n",
    "    \n",
    "    # Remaining data is the test set\n",
    "    test_specimens = list(set(data['Specimen'].unique()) - set(fold))\n",
    "    X_test_fold, y_test_fold = get_data_for_fold(data, test_specimens)\n",
    "    \n",
    "    # Train the model\n",
    "    lolo_rf.fit(X_train_fold.values, y_train_fold.values)\n",
    "    \n",
    "    # Predict on the test set\n",
    "    predictions, uncertainties = lolo_rf.predict(X_test_fold.values, return_std=True)\n",
    "    \n",
    "    # Evaluate the model (you can use your desired metrics here)\n",
    "    # As a placeholder, I'll print the first few predictions for each fold\n",
    "    print(f\"Fold {i+1} Predictions:\", predictions[:5])\n",
    "    print(f\"Fold {i+1} Uncertainties:\", uncertainties[:5])\n",
    "    print('---')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((3126, 11), (782, 11), (3126,), (782,))"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Separate out samples with Label 0 and Label 1\n",
    "class_0 = data[data['Label'] == 0]\n",
    "class_1 = data[data['Label'] == 1]\n",
    "\n",
    "# Randomly sample from the majority class (Class 0) to match the number of samples in Class 1\n",
    "class_0_undersampled = class_0.sample(n=len(class_1), random_state=42)\n",
    "\n",
    "# Combine the undersampled Class 0 samples with Class 1 samples\n",
    "balanced_data = pd.concat([class_0_undersampled, class_1], axis=0).sample(frac=1, random_state=42).reset_index(drop=True)\n",
    "\n",
    "# Split the balanced dataset into training and testing sets using stratified sampling\n",
    "X = balanced_data.drop('Label', axis=1)\n",
    "y = balanced_data['Label']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, stratify=y, random_state=42)\n",
    "\n",
    "X_train.shape, X_test.shape, y_train.shape, y_test.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "ename": "Py4JJavaError",
     "evalue": "An error occurred while calling o44.transform.\n: java.lang.IllegalArgumentException: java.lang.IllegalArgumentException: Self-suppression not permitted\r\n\tat sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)\r\n\tat sun.reflect.NativeConstructorAccessorImpl.newInstance(Unknown Source)\r\n\tat sun.reflect.DelegatingConstructorAccessorImpl.newInstance(Unknown Source)\r\n\tat java.lang.reflect.Constructor.newInstance(Unknown Source)\r\n\tat java.util.concurrent.ForkJoinTask.getThrowableException(Unknown Source)\r\n\tat java.util.concurrent.ForkJoinTask.reportException(Unknown Source)\r\n\tat java.util.concurrent.ForkJoinTask.join(Unknown Source)\r\n\tat scala.collection.parallel.ForkJoinTasks$FJTWrappedTask.sync(Tasks.scala:243)\r\n\tat scala.collection.parallel.ForkJoinTasks$FJTWrappedTask.sync$(Tasks.scala:243)\r\n\tat scala.collection.parallel.AdaptiveWorkStealingForkJoinTasks$AWSFJTWrappedTask.sync(Tasks.scala:304)\r\n\tat scala.collection.parallel.ForkJoinTasks.executeAndWaitResult(Tasks.scala:287)\r\n\tat scala.collection.parallel.ForkJoinTasks.executeAndWaitResult$(Tasks.scala:280)\r\n\tat scala.collection.parallel.ForkJoinTaskSupport.executeAndWaitResult(TaskSupport.scala:59)\r\n\tat scala.collection.parallel.ExecutionContextTasks.executeAndWaitResult(Tasks.scala:410)\r\n\tat scala.collection.parallel.ExecutionContextTasks.executeAndWaitResult$(Tasks.scala:410)\r\n\tat scala.collection.parallel.ExecutionContextTaskSupport.executeAndWaitResult(TaskSupport.scala:75)\r\n\tat scala.collection.parallel.ParIterableLike.map(ParIterableLike.scala:486)\r\n\tat scala.collection.parallel.ParIterableLike.map$(ParIterableLike.scala:485)\r\n\tat scala.collection.parallel.immutable.ParVector.map(ParVector.scala:40)\r\n\tat io.citrine.lolo.bags.BaggedRegressionModel.transform(BaggedModel.scala:45)\r\n\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\r\n\tat sun.reflect.NativeMethodAccessorImpl.invoke(Unknown Source)\r\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(Unknown Source)\r\n\tat java.lang.reflect.Method.invoke(Unknown Source)\r\n\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\r\n\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)\r\n\tat py4j.Gateway.invoke(Gateway.java:282)\r\n\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\r\n\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\r\n\tat py4j.GatewayConnection.run(GatewayConnection.java:238)\r\n\tat java.lang.Thread.run(Unknown Source)\r\nCaused by: java.lang.IllegalArgumentException: Self-suppression not permitted\r\n\tat java.lang.Throwable.addSuppressed(Unknown Source)\r\n\tat scala.collection.parallel.Task.mergeThrowables(Tasks.scala:73)\r\n\tat scala.collection.parallel.Task.mergeThrowables$(Tasks.scala:71)\r\n\tat scala.collection.parallel.ParIterableLike$Map.mergeThrowables(ParIterableLike.scala:1003)\r\n\tat scala.collection.parallel.Task.tryMerge(Tasks.scala:68)\r\n\tat scala.collection.parallel.Task.tryMerge$(Tasks.scala:65)\r\n\tat scala.collection.parallel.ParIterableLike$Map.tryMerge(ParIterableLike.scala:1003)\r\n\tat scala.collection.parallel.AdaptiveWorkStealingTasks$AWSTWrappedTask.internal(Tasks.scala:176)\r\n\tat scala.collection.parallel.AdaptiveWorkStealingTasks$AWSTWrappedTask.internal$(Tasks.scala:156)\r\n\tat scala.collection.parallel.AdaptiveWorkStealingForkJoinTasks$AWSFJTWrappedTask.internal(Tasks.scala:304)\r\n\tat scala.collection.parallel.AdaptiveWorkStealingTasks$AWSTWrappedTask.compute(Tasks.scala:149)\r\n\tat scala.collection.parallel.AdaptiveWorkStealingTasks$AWSTWrappedTask.compute$(Tasks.scala:148)\r\n\tat scala.collection.parallel.AdaptiveWorkStealingForkJoinTasks$AWSFJTWrappedTask.compute(Tasks.scala:304)\r\n\tat java.util.concurrent.RecursiveAction.exec(Unknown Source)\r\n\tat java.util.concurrent.ForkJoinTask.doExec(Unknown Source)\r\n\tat java.util.concurrent.ForkJoinPool$WorkQueue.runTask(Unknown Source)\r\n\tat java.util.concurrent.ForkJoinPool.runWorker(Unknown Source)\r\n\tat java.util.concurrent.ForkJoinWorkerThread.run(Unknown Source)\r\nCaused by: java.lang.OutOfMemoryError: Java heap space\r\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mPy4JJavaError\u001b[0m                             Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[21], line 40\u001b[0m\n\u001b[0;32m     37\u001b[0m lolo_rf\u001b[39m.\u001b[39mfit(X_train_fold\u001b[39m.\u001b[39mvalues, y_train_fold\u001b[39m.\u001b[39mvalues)\n\u001b[0;32m     39\u001b[0m \u001b[39m# Predict on the test set\u001b[39;00m\n\u001b[1;32m---> 40\u001b[0m predictions, uncertainties \u001b[39m=\u001b[39m lolo_rf\u001b[39m.\u001b[39;49mpredict(X_test_fold\u001b[39m.\u001b[39;49mvalues, return_std\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\n\u001b[0;32m     42\u001b[0m \u001b[39m# Placeholder print statement to verify the loop\u001b[39;00m\n\u001b[0;32m     43\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mTraining on Fold \u001b[39m\u001b[39m{\u001b[39;00mi\u001b[39m+\u001b[39m\u001b[39m1\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m with \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mlen\u001b[39m(X_train_fold)\u001b[39m}\u001b[39;00m\u001b[39m samples.\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\gzia\\Documents\\GitHub\\reincarnate_wp2\\.wp2\\Lib\\site-packages\\lolopy\\learners.py:241\u001b[0m, in \u001b[0;36mBaseLoloRegressor.predict\u001b[1;34m(self, X, return_std, return_cov_matrix)\u001b[0m\n\u001b[0;32m    239\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mOnly one of return_std or return_cov_matrix can be True\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m    240\u001b[0m \u001b[39m# Start the prediction process\u001b[39;00m\n\u001b[1;32m--> 241\u001b[0m pred_result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_get_prediction_result(X)\n\u001b[0;32m    243\u001b[0m \u001b[39m# Pull out the expected values\u001b[39;00m\n\u001b[0;32m    244\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_outputs \u001b[39m==\u001b[39m \u001b[39m1\u001b[39m:\n",
      "File \u001b[1;32mc:\\Users\\gzia\\Documents\\GitHub\\reincarnate_wp2\\.wp2\\Lib\\site-packages\\lolopy\\learners.py:210\u001b[0m, in \u001b[0;36mBaseLoloLearner._get_prediction_result\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    207\u001b[0m X_java \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_convert_run_data(X)\n\u001b[0;32m    209\u001b[0m \u001b[39m# Get the PredictionResult\u001b[39;00m\n\u001b[1;32m--> 210\u001b[0m pred_result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmodel_\u001b[39m.\u001b[39;49mtransform(X_java)\n\u001b[0;32m    212\u001b[0m \u001b[39m# Unlink the run data, which is no longer needed (to save memory)\u001b[39;00m\n\u001b[0;32m    213\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mgateway\u001b[39m.\u001b[39mdetach(X_java)\n",
      "File \u001b[1;32mc:\\Users\\gzia\\Documents\\GitHub\\reincarnate_wp2\\.wp2\\Lib\\site-packages\\py4j\\java_gateway.py:1322\u001b[0m, in \u001b[0;36mJavaMember.__call__\u001b[1;34m(self, *args)\u001b[0m\n\u001b[0;32m   1316\u001b[0m command \u001b[39m=\u001b[39m proto\u001b[39m.\u001b[39mCALL_COMMAND_NAME \u001b[39m+\u001b[39m\\\n\u001b[0;32m   1317\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcommand_header \u001b[39m+\u001b[39m\\\n\u001b[0;32m   1318\u001b[0m     args_command \u001b[39m+\u001b[39m\\\n\u001b[0;32m   1319\u001b[0m     proto\u001b[39m.\u001b[39mEND_COMMAND_PART\n\u001b[0;32m   1321\u001b[0m answer \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mgateway_client\u001b[39m.\u001b[39msend_command(command)\n\u001b[1;32m-> 1322\u001b[0m return_value \u001b[39m=\u001b[39m get_return_value(\n\u001b[0;32m   1323\u001b[0m     answer, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mgateway_client, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtarget_id, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mname)\n\u001b[0;32m   1325\u001b[0m \u001b[39mfor\u001b[39;00m temp_arg \u001b[39min\u001b[39;00m temp_args:\n\u001b[0;32m   1326\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mhasattr\u001b[39m(temp_arg, \u001b[39m\"\u001b[39m\u001b[39m_detach\u001b[39m\u001b[39m\"\u001b[39m):\n",
      "File \u001b[1;32mc:\\Users\\gzia\\Documents\\GitHub\\reincarnate_wp2\\.wp2\\Lib\\site-packages\\py4j\\protocol.py:326\u001b[0m, in \u001b[0;36mget_return_value\u001b[1;34m(answer, gateway_client, target_id, name)\u001b[0m\n\u001b[0;32m    324\u001b[0m value \u001b[39m=\u001b[39m OUTPUT_CONVERTER[\u001b[39mtype\u001b[39m](answer[\u001b[39m2\u001b[39m:], gateway_client)\n\u001b[0;32m    325\u001b[0m \u001b[39mif\u001b[39;00m answer[\u001b[39m1\u001b[39m] \u001b[39m==\u001b[39m REFERENCE_TYPE:\n\u001b[1;32m--> 326\u001b[0m     \u001b[39mraise\u001b[39;00m Py4JJavaError(\n\u001b[0;32m    327\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mAn error occurred while calling \u001b[39m\u001b[39m{0}\u001b[39;00m\u001b[39m{1}\u001b[39;00m\u001b[39m{2}\u001b[39;00m\u001b[39m.\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39m\n\u001b[0;32m    328\u001b[0m         \u001b[39mformat\u001b[39m(target_id, \u001b[39m\"\u001b[39m\u001b[39m.\u001b[39m\u001b[39m\"\u001b[39m, name), value)\n\u001b[0;32m    329\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    330\u001b[0m     \u001b[39mraise\u001b[39;00m Py4JError(\n\u001b[0;32m    331\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mAn error occurred while calling \u001b[39m\u001b[39m{0}\u001b[39;00m\u001b[39m{1}\u001b[39;00m\u001b[39m{2}\u001b[39;00m\u001b[39m. Trace:\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m{3}\u001b[39;00m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39m\n\u001b[0;32m    332\u001b[0m         \u001b[39mformat\u001b[39m(target_id, \u001b[39m\"\u001b[39m\u001b[39m.\u001b[39m\u001b[39m\"\u001b[39m, name, value))\n",
      "\u001b[1;31mPy4JJavaError\u001b[0m: An error occurred while calling o44.transform.\n: java.lang.IllegalArgumentException: java.lang.IllegalArgumentException: Self-suppression not permitted\r\n\tat sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)\r\n\tat sun.reflect.NativeConstructorAccessorImpl.newInstance(Unknown Source)\r\n\tat sun.reflect.DelegatingConstructorAccessorImpl.newInstance(Unknown Source)\r\n\tat java.lang.reflect.Constructor.newInstance(Unknown Source)\r\n\tat java.util.concurrent.ForkJoinTask.getThrowableException(Unknown Source)\r\n\tat java.util.concurrent.ForkJoinTask.reportException(Unknown Source)\r\n\tat java.util.concurrent.ForkJoinTask.join(Unknown Source)\r\n\tat scala.collection.parallel.ForkJoinTasks$FJTWrappedTask.sync(Tasks.scala:243)\r\n\tat scala.collection.parallel.ForkJoinTasks$FJTWrappedTask.sync$(Tasks.scala:243)\r\n\tat scala.collection.parallel.AdaptiveWorkStealingForkJoinTasks$AWSFJTWrappedTask.sync(Tasks.scala:304)\r\n\tat scala.collection.parallel.ForkJoinTasks.executeAndWaitResult(Tasks.scala:287)\r\n\tat scala.collection.parallel.ForkJoinTasks.executeAndWaitResult$(Tasks.scala:280)\r\n\tat scala.collection.parallel.ForkJoinTaskSupport.executeAndWaitResult(TaskSupport.scala:59)\r\n\tat scala.collection.parallel.ExecutionContextTasks.executeAndWaitResult(Tasks.scala:410)\r\n\tat scala.collection.parallel.ExecutionContextTasks.executeAndWaitResult$(Tasks.scala:410)\r\n\tat scala.collection.parallel.ExecutionContextTaskSupport.executeAndWaitResult(TaskSupport.scala:75)\r\n\tat scala.collection.parallel.ParIterableLike.map(ParIterableLike.scala:486)\r\n\tat scala.collection.parallel.ParIterableLike.map$(ParIterableLike.scala:485)\r\n\tat scala.collection.parallel.immutable.ParVector.map(ParVector.scala:40)\r\n\tat io.citrine.lolo.bags.BaggedRegressionModel.transform(BaggedModel.scala:45)\r\n\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\r\n\tat sun.reflect.NativeMethodAccessorImpl.invoke(Unknown Source)\r\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(Unknown Source)\r\n\tat java.lang.reflect.Method.invoke(Unknown Source)\r\n\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\r\n\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)\r\n\tat py4j.Gateway.invoke(Gateway.java:282)\r\n\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\r\n\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\r\n\tat py4j.GatewayConnection.run(GatewayConnection.java:238)\r\n\tat java.lang.Thread.run(Unknown Source)\r\nCaused by: java.lang.IllegalArgumentException: Self-suppression not permitted\r\n\tat java.lang.Throwable.addSuppressed(Unknown Source)\r\n\tat scala.collection.parallel.Task.mergeThrowables(Tasks.scala:73)\r\n\tat scala.collection.parallel.Task.mergeThrowables$(Tasks.scala:71)\r\n\tat scala.collection.parallel.ParIterableLike$Map.mergeThrowables(ParIterableLike.scala:1003)\r\n\tat scala.collection.parallel.Task.tryMerge(Tasks.scala:68)\r\n\tat scala.collection.parallel.Task.tryMerge$(Tasks.scala:65)\r\n\tat scala.collection.parallel.ParIterableLike$Map.tryMerge(ParIterableLike.scala:1003)\r\n\tat scala.collection.parallel.AdaptiveWorkStealingTasks$AWSTWrappedTask.internal(Tasks.scala:176)\r\n\tat scala.collection.parallel.AdaptiveWorkStealingTasks$AWSTWrappedTask.internal$(Tasks.scala:156)\r\n\tat scala.collection.parallel.AdaptiveWorkStealingForkJoinTasks$AWSFJTWrappedTask.internal(Tasks.scala:304)\r\n\tat scala.collection.parallel.AdaptiveWorkStealingTasks$AWSTWrappedTask.compute(Tasks.scala:149)\r\n\tat scala.collection.parallel.AdaptiveWorkStealingTasks$AWSTWrappedTask.compute$(Tasks.scala:148)\r\n\tat scala.collection.parallel.AdaptiveWorkStealingForkJoinTasks$AWSFJTWrappedTask.compute(Tasks.scala:304)\r\n\tat java.util.concurrent.RecursiveAction.exec(Unknown Source)\r\n\tat java.util.concurrent.ForkJoinTask.doExec(Unknown Source)\r\n\tat java.util.concurrent.ForkJoinPool$WorkQueue.runTask(Unknown Source)\r\n\tat java.util.concurrent.ForkJoinPool.runWorker(Unknown Source)\r\n\tat java.util.concurrent.ForkJoinWorkerThread.run(Unknown Source)\r\nCaused by: java.lang.OutOfMemoryError: Java heap space\r\n"
     ]
    }
   ],
   "source": [
    "def undersample_data(X, y):\n",
    "    \"\"\"Function to undersample majority class to balance the dataset.\"\"\"\n",
    "    # Combine X and y for easier sampling\n",
    "    data = pd.concat([X, y], axis=1)\n",
    "    \n",
    "    # Separate out samples with Label 0 and Label 1\n",
    "    class_0 = data[data['Label'] == 0]\n",
    "    class_1 = data[data['Label'] == 1]\n",
    "    \n",
    "    # Randomly sample from the majority class (Class 0) to match the number of samples in Class 1\n",
    "    class_0_undersampled = class_0.sample(n=len(class_1), random_state=42)\n",
    "    \n",
    "    # Combine the undersampled Class 0 samples with Class 1 samples\n",
    "    balanced_data = pd.concat([class_0_undersampled, class_1], axis=0).sample(frac=1, random_state=42).reset_index(drop=True)\n",
    "    \n",
    "    # Split the combined data back into X and y\n",
    "    X_balanced = balanced_data.drop('Label', axis=1)\n",
    "    y_balanced = balanced_data['Label']\n",
    "    \n",
    "    return X_balanced, y_balanced\n",
    "\n",
    "# Train and test using custom folds\n",
    "for i, fold in enumerate(folds):\n",
    "    # Split the data\n",
    "    X_train_fold, y_train_fold = get_data_for_fold(data, fold)\n",
    "    \n",
    "    # Perform undersampling on the training data\n",
    "    X_train_fold, y_train_fold = undersample_data(X_train_fold, y_train_fold)\n",
    "    \n",
    "    # Remaining data is the test set\n",
    "    test_specimens = list(set(data['Specimen'].unique()) - set(fold))\n",
    "    X_test_fold, y_test_fold = get_data_for_fold(data, test_specimens)\n",
    "    \n",
    "    # Train the model\n",
    "    # Note: I'm commenting out the model training and prediction lines since we don't have lolopy installed.\n",
    "    # You can uncomment and run them in your local setup.\n",
    "    lolo_rf.fit(X_train_fold.values, y_train_fold.values)\n",
    "    \n",
    "    # Predict on the test set\n",
    "    predictions, uncertainties = lolo_rf.predict(X_test_fold.values, return_std=True)\n",
    "    \n",
    "    # Placeholder print statement to verify the loop\n",
    "    print(f\"Training on Fold {i+1} with {len(X_train_fold)} samples.\")\n",
    "    # Print the first few predictions for each fold\n",
    "    print(f\"Fold {i+1} Predictions:\", predictions[:5])\n",
    "    print(f\"Fold {i+1} Uncertainties:\", uncertainties[:5])\n",
    "    print('---')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Another try"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the dataset\n",
    "data = pd.read_excel(\"open_crosion.xlsx\")\n",
    "\n",
    "# Display the first few rows\n",
    "data.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Extract features and target\n",
    "X = data[['Feature 1', 'Feature 2', 'Feature 3', 'Feature 4', 'Feature 5', 'Feature 6', 'Feature 7']]\n",
    "y = data['Label']\n",
    "\n",
    "# Split the data into training and testing sets (80% training, 20% testing)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict using the trained model\n",
    "predictions, uncertainties = rf.predict(np.array(X_test), return_std=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Filter the data by specimen\n",
    "specimen_1_indices = data['Specimen'][X_test.index] == 1\n",
    "specimen_2_indices = data['Specimen'][X_test.index] == 2\n",
    "\n",
    "# Create the plot\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.scatter(np.arange(sum(specimen_1_indices)), uncertainties[specimen_1_indices], label='Specimen 1', alpha=0.6)\n",
    "plt.scatter(np.arange(sum(specimen_2_indices)), uncertainties[specimen_2_indices], label='Specimen 2', alpha=0.6)\n",
    "plt.title('Uncertainty by Specimen')\n",
    "plt.ylabel('Uncertainty')\n",
    "plt.xlabel('Sample Index')\n",
    "plt.legend()\n",
    "plt.grid(True, which='both', linestyle='--', linewidth=0.5)\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".wp2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
